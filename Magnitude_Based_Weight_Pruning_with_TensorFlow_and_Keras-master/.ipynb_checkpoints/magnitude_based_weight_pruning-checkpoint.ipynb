{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"images/0.jpg\" alt=\"Pruning Trees\" style=\"width:100%;\">\n",
    "    <h1>Magnitude-Based Weight Pruning with Keras</h1>\n",
    "      <br/>\n",
    "      <p>\n",
    "          Nowadays Deep Learning models require a significant amount of computing, memory, and power to be developed, deployed \n",
    "          and used, this creates an impediment in the conditions where real-time inference it is a priority or even when \n",
    "          running models on edge devices and browsers with limited computational resources. A major concern for current deep \n",
    "          learning models is <b>Energy efficiency</b>. A technique for dealing with this efficiency is enabling inference \n",
    "          efficiency and this is done through <b><i>Magnitude-Based Weight Pruning</i></b>.\n",
    "      </p>\n",
    "  </div>\n",
    "</div>\n",
    "<p>\n",
    "    <br/>\n",
    "    <b>What is weight pruning?</b>\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Magnitude-based weight pruning gradually zeroes out model weights during the training process to achieve model sparsity. \n",
    "    Sparse models are easier to compress, and as it allows to skip the zeroes during inference for achieving latency \n",
    "    improvements.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    This technique brings improvements via model compression.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    The technique is being evaluated in various speech applications, such as speech recognition and text-to-speech, and has \n",
    "    been experimented on across various vision and translation models.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Through elimination of unnecessary values in the weight tensor, it is setting neural network parameters values to zero to \n",
    "    remove low-weight connections between the layers of a neural network.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    <b>Why is useful?</b>\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Tensors with several values set to zero can be considered sparse. This results in important benefits:\n",
    "    <ul>\n",
    "    <li><b>Compression</b>: Sparse tensors are amenable to compression by only keeping the non-zero values and their \n",
    "        corresponding coordinates.</li>\n",
    "    <li><b>Speed</b>: Sparse tensors allow to skip otherwise unnecessary computations involving the zero values.</li>\n",
    "    <li><b>Performance</b>: Sparse tensors by allowing to skip otherwise unnecessary computations involving the zero values,\n",
    "        the neural network can generalized information better, leading to a perfomance gained.</li>\n",
    "    </ul>\n",
    "    <br/>\n",
    "    <b>How does it work?</b>\n",
    "    <br/>\n",
    "    <br/>\n",
    "    The <b><i>Keras-Based Weight Pruning API</i></b> is designed to iteratively remove connections based on their magnitude, \n",
    "    during training.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    This notebook, explains an end-to-end example of using the Keras-Based Weight Pruning API on a simple MNIST model. It will\n",
    "    demostrate that by simply using a generic file compression algorithm (e.g. zip) the Keras model will be reduced in size and \n",
    "    that this size reduction persists when converted to a Tensorflow Lite format for devices with limited computacional \n",
    "    resources.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Two things worth clarifying:\n",
    "    <ul>\n",
    "        <li><b><i>Magnitude-Based Weight Pruning</i></b> technique and the <b><i>Keras-Based Weight Pruning API</i></b> are not \n",
    "            TensorFlow Lite specific, this notebook just demostrates its application on the TensorFlow Lite backend, as it \n",
    "            covers size-sensitive use-cases.</li>\n",
    "    <li>A sparse model will not be faster to execute, <b><i>by itself!</b></i>. It just enables backends with such capability.<i> According to the official documentation of Tensorflow, in the near future, however, TensorFlow Lite will take advantage of the sparsity to speed up computations</i>.</li>\n",
    "    </ul>\n",
    "    <br/>\n",
    "    This notebook is divided by the next sections:\n",
    "    <ul>\n",
    "        <li>Training a MNIST model with Keras from scratch.</li>\n",
    "        <li>Training a pruned MNIST with the Pruning API.</li>\n",
    "        <li>Comparing the size of the pruned model and the non-pruned one after compression.</li>\n",
    "        <li>Converting the pruned model to Tensorflow Lite format and verify that accuracy persists.</li>\n",
    "        <li>Demonstrating how the pruned model works with other optimization techniques, like <a href=''>post-training quantization</a>.</li>\n",
    "    </ul>\n",
    "    <h2>Set Up</h2>\n",
    "    <br/>\n",
    "    To use Keras-Based Weight Pruning API, it is needed to install the <code>tensorflow-model-optimization</code> package. \n",
    "    Check the <a href='https://github.com/tensorflow/model-optimization'>TensorFlow model optimization repo</a> for API \n",
    "    versions compatibility.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    In this notebook few models will be train, it is recommended but not necessary to install the <code>tensorflow-gpu</code>\n",
    "    package to speed up things.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-gpu 2.1.0\n",
      "Uninstalling tensorflow-gpu-2.1.0:\n",
      "  Successfully uninstalled tensorflow-gpu-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tf-nightly-gpu as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow-gpu\n",
    "!pip uninstall -y tf-nightly-gpu\n",
    "!pip install -q -U tensorflow-gpu\n",
    "\n",
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Necessary Packages, Modules & Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Brief Introduction to Tensorboard</h4>\n",
    "<br/>\n",
    "In machine learning, to improve something you often need to be able to measure it.\n",
    "<code>tensorboard</code>: TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
    "<br/>\n",
    "<br/>\n",
    "If an alert emerges, saying <code>The tensorboard module is not an IPython extension.</code> from importing <code>tensorboad</code>, by following <a href='https://www.dlology.com/blog/how-to-run-tensorboard-in-jupyter-notebook/'>this guide</a> can be resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By importing Tensorflow, it is now possible to automatically use enable eager execution.\n",
    "<br/>\n",
    "<br/>\n",
    "<b>What is Eager Execution?</b>\n",
    "<br/>\n",
    "<br/>\n",
    "According to <a href='https://www.tensorflow.org/guide/eager'>Tensorflow Guide</a> this is Eager Execution:\n",
    "<br/>\n",
    "<br/>\n",
    "<div style='background-color:#f1fbff;padding:2%;'>\n",
    "    TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without \n",
    "    building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes \n",
    "    it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well. To follow along with this \n",
    "    guide, run the code samples below in an interactive python interpreter.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Eager execution is a flexible machine learning platform for research and experimentation, providing:\n",
    "    <ul>\n",
    "        <li><i>An intuitive interface</i>—Structure your code naturally and use Python data structures. Quickly iterate on }\n",
    "            small models and small data.</li>\n",
    "        <li><i>Easier debugging</i>—Call ops directly to inspect running models and test changes. Use standard Python debugging \n",
    "            tools for immediate error reporting.</li>\n",
    "        <li><i>Natural control flow</i>—Use Python control flow instead of graph control flow, simplifying the specification of \n",
    "            dynamic models.</li>\n",
    "    </ul>\n",
    "    Eager execution supports most TensorFlow operations and GPU acceleration.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By importing the modudle <code>tempfile</code> it is possible to generate temporary files and directories.\n",
    "<br/>\n",
    "Thanks to the module <code>zipfile</code> and its tools it is possible to create, read, write, append, and list a ZIP file.\n",
    "<br/>\n",
    "The <code>os</code> provides a portable way of using operating system dependent functionality.\n",
    "<br/>\n",
    "<h3>Preparing Training Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "# Input Image Dimensions\n",
    "IMG_ROWS, IMG_COLS = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, IMG_ROWS, IMG_COLS)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, IMG_ROWS, IMG_COLS)\n",
    "    INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], IMG_ROWS, IMG_COLS, 1)\n",
    "    INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Preprocessing</h4>\n",
    "<ul>\n",
    "    <li>Convert features into <code>float32</code> data type.</li>\n",
    "    <li>Divide features by 255 as standardization.</li>\n",
    "    <ul>\n",
    "        <li>Show train tensor shape.</li>\n",
    "        <li>Show train and test length samples.</li>\n",
    "    </ul>\n",
    "    <li>Convert class vectors (or labels) to binary class matricess, Label Encoding.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training a MNIST model without pruning</h2>\n",
    "<h4>Building a Convolutional Neuronal Network from Scratch! This the MNIST model.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layer.Conv2D(32, 5, padding='same', activation='relu', input_shape=INPUT_SHAPE),\n",
    "    layer.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layer.BatchNormalization(),\n",
    "    layer.Conv2D(64, 5, padding='same', activation='relu'),\n",
    "    layer.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layer.Flatten(),\n",
    "    layer.Dense(1024, activation='relu'),\n",
    "    layer.Dropout(0.4),\n",
    "    layer.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Convolutional Neuronal Network MNIST model architecture built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load TensorBoard to monitor the training process</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training logs to C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpp7_wbg31\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training the MNIST model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1844 - accuracy: 0.9507 - val_loss: 0.1183 - val_accuracy: 0.9810\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0262 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0267 - val_accuracy: 0.9906\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0229 - val_accuracy: 0.9925\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0306 - val_accuracy: 0.9893\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0281 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0262 - val_accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0288 - val_accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0358 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0290 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02898943738769276\n",
      "Test accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Save the original model for size comparison later</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to:  C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpnlknlmv5mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Backend agnostic way to save/restore models\n",
    "_, keras_file = tempfile.mkstemp('mnist_model.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training a Pruned MNIST Model with Pruning API</h2>\n",
    "<br/>\n",
    "<p>\n",
    "    The <code>prune_low_magnitude()</code> API provides the ability to train models with removed connections. The <code>Keras-based</code> API can be applied at the level of individual layers or the entire model, in this notebook both options will be applied and explained.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    At a high level, given an schedule and a target sparsity the technique qorks by iteratively removing (i.e. zeroing out) connections between layers.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    An example, a regular configuration by targetin a 75% sparsity and by pruning connections (aka synapses) every 100 steps (aka epochs), starting from step 2,000.\n",
    "    <br/>\n",
    "    <img src=\"images/2.png\" style=\"width:60%;height:600%\"/>\n",
    "    <h3>Building a Pruned Model Layer by Layer</h3>\n",
    "    <br/>\n",
    "    By building this pruned model, <i><b>its shown how to use the API at the level of layers, and build a pruned MNIST solver \n",
    "    model.</i></b>\n",
    "    <br/>\n",
    "    <br/>\n",
    "    In this example, the <code>prune_low_magnitude()</code> <b>will recive as parameter the Keras layer whose weights are \n",
    "    wanted for pruning</b>.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    The <code>prune_low_magnitude()</code> function requires a pruning params, this pruning params configures the pruning algorithm during training. If it is wanted to have and known detailed documentation about this puring params, <a href='https://github.com/tensorflow/model-optimization'>the official github repository</a> offers a more in depth explanation and guide to this pruning params. The parameter used here means:\n",
    "    <ul>\n",
    "        <li><b>Sparsity</b>: <code>PolynomialDecay</code> is used through the training process. The training process starts \n",
    "            with a sparsity level of 50% and by gradually training the model to reach 90% sparsity. <b>X% sparsity means that \n",
    "            X% of the weight tensor is going to be pruned away</b>. In the beginning the pruning rate grows rapidly from \n",
    "            <code>initial_sparsity</code>, but then plateaus slowly to the target sparsity, which is the \n",
    "            <code>final_sparsity</code>. The function applied is:\n",
    "            <br/>\n",
    "            <br/>\n",
    "            <div style=\"text-align:center;\">\n",
    "                $s_t=s_f+(s_i - s_f) (1 - \\frac{t - t_0}{n \\Delta t})^3\\quad\\text{for $\\quad t$} \\in \\text{{$t_0,  t_0 + \\Delta \n",
    "                t, \\cdots, t_0 + n \\Delta t $}}$\n",
    "            </div>\n",
    "            Symbols meaning:\n",
    "            <ul style=\"list-style-type:none;\">\n",
    "                <li>$s_t$: Desired sparsity level.</li>\n",
    "                <li>$s_i$: Initial sparsity value.</li>\n",
    "                <li>$s_f$: Final sparsity value.</li>\n",
    "                <li>$t$:   Current training step.</li>\n",
    "                <li>$t_0$: Initial training step.</li>\n",
    "                <li>$n$:   Span of pruning steps.</li>\n",
    "                <li>$\\Delta t$: Pruning frequency, <i><b>Schedule</i></b>.</li>\n",
    "            </ul>\n",
    "            <br/>\n",
    "        </li>\n",
    "        <li><b>Schedule</b>: Starting from step 2000 to the end of training, connections are pruned and every 100 steps runs as \n",
    "            schedule. This is because as it is wanted to train the model without pruning for a few epochs to reach a \n",
    "            certain accuracy, to aid convergence. Furthermore, the model is given some time to recover after each pruning step, \n",
    "            therefore <i><b>pruning does not happen on every step</i></b>. The pruning frequency (aka <i>schedule</i> or \n",
    "            $\\Delta t$) is set \n",
    "            to 100.</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow, the training of the pruned Keras model starts, the model will start its training and at its 10 first epochs, the model will be saved in the disk and will be finally restored for continue training for 2 epochs.\n",
    "<br/>\n",
    "Thanks to gradual sparsity, there are four important parameters:\n",
    "<ul>\n",
    "    <li><code>begin_sparsity</code>.</li>\n",
    "    <li><code>final_sparsity</code>.</li>\n",
    "    <li><code>begin_step</code>.</li>\n",
    "    <li><code>end_step</code>.</li>\n",
    "</ul>\n",
    "To calculate the <code>end step</code> parameter is done through the given number of train example, batch size and the total epochs to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step value: 5628\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Epochs for Pruning Model\n",
    "EPOCHS_PM = 12\n",
    "NUM_TRAIN_SAMPLES = x_train.shape[0]\n",
    "END_STEP = np.ceil(1.0 * NUM_TRAIN_SAMPLES / BATCH_SIZE).astype(np.int32) * EPOCHS_PM\n",
    "print('End step value: ' + str(END_STEP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the dictionary of keyword arguments (<b>**kwargs</b>) <code>pruning_params</code> is created, it holds a the keyword <code>pruning_schedule</code> and the subclass <code>PolynomialDecay</code> from the class <code>sparsity</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=2000,\n",
    "                                                   end_step=END_STEP,\n",
    "                                                   frequency=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequential <code>pruned_model</code> model is defined and the <code>prune_low_magnitude()</code> functions recives as parameter the Keras layer whose weights are wanted and be pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:183: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "pruned_model = tf.keras.Sequential([\n",
    "    sparsity.prune_low_magnitude(layer.Conv2D(32, 5, padding='same', activation='relu'), input_shape=INPUT_SHAPE, **pruning_params),\n",
    "    layer.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layer.BatchNormalization(),\n",
    "    sparsity.prune_low_magnitude(layer.Conv2D(64, 5, padding='same', activation='relu'), **pruning_params),\n",
    "    layer.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
    "    layer.Flatten(),\n",
    "    sparsity.prune_low_magnitude(layer.Dense(1024, activation='relu'), **pruning_params),\n",
    "    layer.Dropout(0.4),\n",
    "    sparsity.prune_low_magnitude(layer.Dense(NUM_CLASSES, activation='softmax'), **pruning_params)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple architecture of the model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_4 (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_5 (None, 14, 14, 64)        102466    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 1024)              6423554   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_4  (None, 10)                20492     \n",
      "=================================================================\n",
      "Total params: 6,548,274\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 3,273,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Tensorboard</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training logs to C:\\Users\\kleye\\AppData\\Local\\Temp\\tmptq2j1h2s\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training the Pruned MNIST Model</h4>\n",
    "<br/>\n",
    "The pruning starts from step 2000<sup>th</sup>, <b>when the accuracy of the model is lower than 98%!</b>\n",
    "<br/>\n",
    "<br/>\n",
    "The <code>prunde_model</code> is compile, with:\n",
    "<ul>\n",
    "    <li><code>categorical_crossentropy</code> as loss function.</li>\n",
    "    <li><code>adam</code> as the optimizer.</li>\n",
    "    <li><code>accuracy</code> as the metric for evaluation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using <code>callbacks</code> parameter, a pruning step callback is added to peg the pruning step to the optimizer's\n",
    "step and also is added a callback to add pruning summaries to <code>Tensorboard</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The model is ready to be trained and pruned!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9450 ETA: 1s - lINFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2103 - accuracy: 0.9453 - val_loss: 0.0781 - val_accuracy: 0.9863\n",
      "Epoch 2/10\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9856INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.0276 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9897INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.0286 - val_accuracy: 0.9903\n",
      "Epoch 4/10\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9909INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9934INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0234 - val_accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9947INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0245 - val_accuracy: 0.9929\n",
      "Epoch 7/10\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9949INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.0236 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9956INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0231 - val_accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9955INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0223 - val_accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "59264/60000 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9956INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0215 - val_accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2574fe3af60>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to check the results of the <code>pruned_model</code>.\n",
    "<h4>Is pruning working?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.021509590928414035\n",
      "Test accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "score = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruning has not been completed, there are still 2 more epochs to complete the pruning optimization, but the current results until now are slightly overcomming the result obtained from the regular model, the table displays a comparative between the losses and accuracies of both models.\n",
    "\n",
    "<br/>\n",
    "<table style=\"border: 1px solid #ddd;text-align: left;border-collapse: collapse;width: 50%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Model Type</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Loss</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Regular MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0289</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9907</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0215</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9931</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br/>\n",
    "<h4>Save and Restore the Pruned MNIST Model</h4>\n",
    "<br/>\n",
    "In this part of the notebook, the training will be finished by completing the two remaining epochs, but first a checkpoint file must be prepared for saving the <code>pruned_model</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpyy1fnkcnpruned_mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "_, checkpoint_pruned_model_file = tempfile.mkstemp('pruned_mnist_model.h5')\n",
    "print('Saving pruned model to: ', checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>saved_model()</code> sets <code>include_optimizer</code> to <code>True</code> by default, because it is <b>required</b> to preserve the state of the optimizer across training sessions for pruning to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(pruned_model, checkpoint_pruned_model_file, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <code>prune_scope()</code> allows to load a model that has been pruned before. When loading a pruned model, it has to be loaded by the <code>prune_scope()</code> function for deseriazliation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sparsity.prune_scope():\n",
    "    restored_pruned_mnist_model = tf.keras.models.load_model(checkpoint_pruned_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the <code>callbacks</code>, in this case is set up just as before, if wanted different callback can be integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit the restore pruned model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9970INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0242 - val_accuracy: 0.9926\n",
      "Epoch 2/2\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9977INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_4_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_5_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_4_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_4_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_4_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_5_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_5_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_4_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_4_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0232 - val_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2575528d128>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_pruned_mnist_model.fit(x_train, y_train,\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=2,\n",
    "                   verbose=1,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Did the pruned model still beat regular model?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02319358599687448\n",
      "Test accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "score = restored_pruned_mnist_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruning has been completed, there are still more steps to properly finish this optimization technique. The final results from training for two more epochs has been calculated with a slightly decrease in the accuracy and a slightly increament in the loss function the pruned model trained for 12 epochs, did not performed as well as the pruned model trained by 10 epochs, <i><b>but both pruned models performed better in accuracies and losses than the accuracy and loss of the regular model.</i></b> The table below displays a comparative between the losses and accuracies of the models.\n",
    "\n",
    "<br/>\n",
    "<table style=\"border: 1px solid #ddd;text-align: left;border-collapse: collapse;width: 80%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Model Type</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Epochs</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Loss</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Regular MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0289</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9907</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0215</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9931</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Restored Pruned MNIST Model</td>\n",
    "      <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>2</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0231</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9928</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br/>\n",
    "<h4>Exporting Preparation for Model Serving by <i>Striping the pruning wrappers from the Pruned Model</i></h4>\n",
    "<br/> \n",
    "When the time for exporting a serving model comes, it must be needee to call the <code>strip_pruning()</code> API, the <code>strip_pruning()</code> will strip the pruning wrappers from the model, because it was only needed for training. It is essential to remember that the pruning wrappers are only needed for training.\n",
    "<br/>\n",
    "<br/>\n",
    "The model for serving, is selected by the one with best perfomance in its loss function and metric(s). In this situtation the best model is the <code>pruned_model</code> with a loss function of 0.0215 and an accuracy of 0.9931."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_model = sparsity.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "serving_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again a checkpoint file, must be created, this is specifically for the final model, which is the <code>serving_model</code>, <b>this model is the one that will be deployed into production!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpjnu9v28zserving_model.h5\n"
     ]
    }
   ],
   "source": [
    "_, checkpoint_serving_model_file = tempfile.mkstemp('serving_model.h5')\n",
    "print('Saving pruned model to: ', checkpoint_serving_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need of saving the optimizer with the graph for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(serving_model, checkpoint_serving_model_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Comparing the Size of the Pruned Model and the Non-Pruned One After Compression</h2>\n",
    "<br/>\n",
    "Here by using the <code>tempfile.mkstemp()</code> class and its function, a temp zip file is created, then that file will have compressed the model, then the size of the model before and after compression will be displayed for matters of comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unpruned model before compression: 12.52 Mb\n",
      "Size of the unpruned model after compression: 11.59 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_keras_file = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip_keras_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "\n",
    "print(\"Size of the unpruned model before compression: %.2f Mb\" % (os.path.getsize(keras_file) / float(2**20)))\n",
    "print(\"Size of the unpruned model after compression: %.2f Mb\" % (os.path.getsize(zip_keras_file) / float(2**20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 12.52 Mb\n",
      "Size of the pruned model after compression: 2.50 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_serving_model_file = tempfile.mkstemp('.zip') \n",
    "with zipfile.ZipFile(zip_serving_model_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(checkpoint_serving_model_file)\n",
    "\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % (os.path.getsize(checkpoint_serving_model_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % (os.path.getsize(zip_serving_model_file) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: 1px solid #ddd;text-align: left;border-collapse: collapse;width: 100%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Model Type</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Epochs</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Loss</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Accuracy</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Size Before .zip</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Size After .zip</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Regular MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0289</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9907</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">12.52 MB</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">11.59 MB</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Serving Model<br/>*Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0215</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9931</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">12.52 MB</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">2.51 MB</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br/>\n",
    "It is clear to see the benefits from Magnitude Based Weight Pruning and Compressing Pruned Models, until now those benefits are:\n",
    "<ul>\n",
    "    <li>Lower loss function.</li>\n",
    "    <li>Higher accuracy score.</li>\n",
    "    <li>Faster inference.</li>\n",
    "    <li>Lighter models.</li>\n",
    "</ul>\n",
    "In this case by compressing an unpruned model its size was only reduced from <b>12.42 Mb</b> to <b>11.59 Mb</b>, a poor reduction of <b>+0.08</b> times and for the pruned model, its initial size was <b>12.42 Mb</b> and by applying compressing its size was reduced to <b>2.51 Mb</b>, an extremely huge reduction, its size was reduced by <b>+4.98</b> times!, <b>prunnig and compressing techniques, an excellent duo for applying to machine learning models.</b>\n",
    "<br>\n",
    "<h4>Pruning a Whole Model</h4>\n",
    "<br/>\n",
    "<code>prune_low_magnitude</code> function can also be applied to the entire Keras model, the algorithm will be applied to all layers that are ameanable to weight pruning (that the API knows about). Layers that the API knows are not ameanable to weight pruning will be ignored, and unknown layers to the API will cause an error.\n",
    "<br/>\n",
    "<br/>\n",
    "If the model has layers that the API does not know how to prune their weights, but are perfectly fine to leave \"un-pruned\", it is possible to apply the API in a per-layer basis.\n",
    "<br/>\n",
    "<br/>\n",
    "Regarding pruning configuration, the same settings apply to all prunable layers in the model.\n",
    "<br/>\n",
    "<br/>\n",
    "<div style=\"background-color:#e7f3fe;padding:15px;width:50%;height:50%;margin:auto;text-align:center;\">\n",
    "  <p style=\"\">\n",
    "      <strong>Note:</strong>\n",
    "      Pruning doesn't preserve the optimizer associated with the original model. As a result, it is necessary to re-compile the \n",
    "      pruned model with a new optimizer.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "This example will be developed by using an already existing model, which it is serialized, by taking the original MNIST regular model trained previously. Now starting by loading the serialized model into memory like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to prune the model loaded and compile the pruned model for training. Recap some conditions for preparing the model for pruning optimization:\n",
    "<ul>\n",
    "    <li>For this case training will restart from step 0.</li>\n",
    "    <li>As the loaded model has already reached a satisfactory accuracy, pruning can be started inmediately.</li>\n",
    "    <li>The parameter <code>begin_step</code> is set to 0.</li>\n",
    "    <li>Train the loaded model by some certain epochs, in this case the constant <code>EPOCHS_WKM</code> referes to the epochs for training the whole Keras model.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_WKM = 4\n",
    "END_STEP = np.ceil(1.0 * NUM_TRAIN_SAMPLES / BATCH_SIZE).astype(np.int32) * EPOCHS_WKM\n",
    "print(END_STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Them the dictionary of keyword arguments (**kwargs) <code>new_pruning_params</code> is created, it holds a the keyword pruning_schedule and the subclass PolynomialDecay from the class sparsity and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=END_STEP,\n",
    "                                                   frequency=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model as <code>new_pruned_model</code>, with the class <code>sparsity</code> and its function <code>prune_low_magnitude()</code>, the model <code>loaded_model</code> is passed as a parameter and the dictionary of keyword arguments <code>new_pruning_params</code> is also passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the <code>model</code> architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d ( (None, 28, 28, 32)        1634      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_batch_no (None, 14, 14, 32)        129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 14, 14, 64)        102466    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 7, 7, 64)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 3136)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 1024)              6423554   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dropout  (None, 1024)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 10)                20492     \n",
      "=================================================================\n",
      "Total params: 6,548,279\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 3,273,581\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Time to compile </b><code>new_pruned_model</code><b>!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tensorboard, again.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training logs to C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpoyzfxx2i\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('Writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the Model for Another <i>Four</i> Epochs</h4>\n",
    "<br/>\n",
    "Create a callback for adding a pruning step callback to peg the pruning step to the optimizer's step. Also add another callback to add pruning summaries to <code>Tensorboard</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fit</b> the <code>new_pruned_model</code> and wait for the results of its loss function and its metric score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9962INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/mask:0/sparsity is illegal; using prune_low_magnitude_dense_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/threshold:0/threshold is illegal; using prune_low_magnitude_dense_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
      "Epoch 2/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985 ETA: 0s - lINFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/mask:0/sparsity is illegal; using prune_low_magnitude_dense_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/threshold:0/threshold is illegal; using prune_low_magnitude_dense_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0253 - val_accuracy: 0.9937\n",
      "Epoch 3/4\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/mask:0/sparsity is illegal; using prune_low_magnitude_dense_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/threshold:0/threshold is illegal; using prune_low_magnitude_dense_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
      "Epoch 4/4\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/mask:0/sparsity is illegal; using prune_low_magnitude_dense_5/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1_2/mask_0/sparsity instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1_2/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_5/threshold:0/threshold is illegal; using prune_low_magnitude_dense_5/threshold_0/threshold instead.\n",
      "INFO:tensorflow:Summary name prune_low_magnitude_dense_1_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1_2/threshold_0/threshold instead.\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0297 - val_accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2575fbfde10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pruned_model.fit(x_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS_WKM,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Did the Whole Pruned Model Beat the custom pruned model and regular model?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.029654509916423388\n",
      "Test accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "score = new_pruned_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pruned whole model, performs slightly better than the others models:\n",
    "<br/>\n",
    "<table style=\"border: 1px solid #ddd;text-align: left;border-collapse: collapse;width: 80%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Model Type</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Epochs</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Loss</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Whole Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>4</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0296</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9936</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0215</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9931</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Restored Pruned MNIST Model</td>\n",
    "      <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>2</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0231</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9928</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Regular MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0289</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9907</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br/>\n",
    "<h4>Exporting the Pruned Whole Model for Serving</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_whole_pruned_model = sparsity.strip_pruning(new_pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last look at its arch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_whole_pruned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparing for Saving the Whole Pruned Model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  C:\\Users\\kleye\\AppData\\Local\\Temp\\tmpzeb2lnfofinal_whole_pruned_model.h5\n"
     ]
    }
   ],
   "source": [
    "_, new_pruned_keras_file = tempfile.mkstemp('final_whole_pruned_model.h5')\n",
    "print('Saving pruned model to: ', new_pruned_keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Save the whole pruned model ready for being deployed into production!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(final_whole_pruned_model, new_pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compressing the Whole Pruned Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 12.52 Mb\n",
      "Size of the pruned model after compression: 2.42 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_final_whole_pruned_model = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_final_whole_pruned_model, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(new_pruned_keras_file)\n",
    "\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" % (os.path.getsize(new_pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" % (os.path.getsize(zip_final_whole_pruned_model) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>final_whole_pruned_model</code> it is to have a size of <b>12.52 Mb</b> before compression, after compressing the model its new size went down to <b>2.42 Mb</b>, amazing <b>+5.17</b> times lighter. Its comparison with the other models:\n",
    "<br/>\n",
    "<table style=\"border: 1px solid #ddd;text-align: left;border-collapse: collapse;width: 80%;\">\n",
    "  <tr>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Model Type</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Epochs</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Total of Epochs</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Loss</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Accuracy</th>  \n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Size Before .zip</th>\n",
    "    <th style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Size After .zip</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Whole Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>4</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>14</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0296</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9936</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">12.52 MB</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">2.42 MB</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0215</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9931</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">12.52 MB</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">2.51 MB</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Restored Pruned MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>2</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\"><i>12</i></td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0231</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9928</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Not Calculated</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Not Calculated</td>  \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">Regular MNIST Model</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">10</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.0289</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">0.9907</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">12.52 MB</td>\n",
    "    <td style=\"border: 1px solid #ddd;text-align: left;padding: 10px;\">11.59 MB</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<br/>\n",
    "Definetly the <code>final_whole_pruned_model</code> it is the best model in terms of metrics scores and size, but its loss functions its the worst of the losses functions from the models.\n",
    "<br/>\n",
    "<h2>Converting to TensorFlow Lite</h2>\n",
    "<br/>\n",
    "Converting the whole pruned model to a format that's runnable on the targeting backend. <code>Tensorflow Lite</code> is an example format that can be used to deploy to mobile devices. To convert to a <code>Tensorflow Lite</code> graph, it is needed use the <code>TFLiteConverter</code> as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = 'C:/Users/kleye/AppData/Local/Temp/mpzeb2lnfofinal_whole_pruned_model.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_whole_pruned_model)\n",
    "#tflite_model = converter.convert()\n",
    "# /\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    # f.write(tflite_model)\n",
    "    f.write(converter.convert())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Compressing the TensorFlow Lite Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 12.49 Mb\n",
      "Size of the tflite model after compression: 2.31 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(tflite_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" % (os.path.getsize(tflite_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As <code>TensorFlow Lite</code> is a lighter version of <code>TensorFlow</code>, for mobile devices, the model had <b>12.49 Mb</b> and after compressing it, its new size is <b>2.31 Mb</b>, a reduction of <b>+5.4</b> times.\n",
    "<br/>\n",
    "<h3>Evaluating the Accuracy of the TensorFlow Lite Model</h3>\n",
    "<br/>\n",
    "The <code>Interpreter</code> class is an interpreter for a graph of nodes that input and output from tensors, each node of the graph processes a set of input tensors and produces a set of output Tensors. All inputs/output tensors are referenced by index.\n",
    "<br/>\n",
    "<br/>\n",
    "The <code>allocate_tensors()</code> updates allocations for all tensors. This will redim dependent tensors using the input tensor dimensionality as given. This is relatively expensive. If you know that your sizes are not changing, you need not call this. Returns status of success or failure.\n",
    "<br/>\n",
    "<br/>\n",
    "The <code>get_input_details()</code> function gets the input models details, in this case it returns the value of <code>INPUTE_SHAPE</code>, a list of input details.\n",
    "<br/>\n",
    "<br/>\n",
    "The <code>get_output_details()</code> functions get model output details and it returns a list of output details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method <code>eval_model</code>, evaluates the performance of the <code>TFLite</code> model and returns its accuracy. Inside this method there are three functions that are worth to explain and they are:\n",
    "<ul>\n",
    "    <li><code>set_tensor()</code>: Sets the value of the input tensor.</li>\n",
    "    <li><code>invoke()</code>: Invokes the interpreter. Be sure to set the input sizes, allocate tensors and fill values before \n",
    "        calling this. Also, note that this function releases the GIL so heavy computation can be done in the background while \n",
    "        the Python interpreter continues. No other function on this object should be called while the invoke() call has not \n",
    "        finished.</li>\n",
    "    <li><code>get_tensor()</code>:  Gets the value of the input tensor (get a copy), this function cannot be used to read \n",
    "        intermediate results, this function returns a numpy array. If it is wished to avoid the copy, therefore the function \n",
    "        <code>tensor()</code> should be used.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(interpreter, x_test, y_test):\n",
    "    total_seen = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    for img, label in zip(x_test, y_test):\n",
    "        inp = img.reshape((1, 28, 28, 1))\n",
    "        total_seen += 1\n",
    "        interpreter.set_tensor(input_index, inp)\n",
    "        interpreter.invoke()\n",
    "        predictions = interpreter.get_tensor(output_index)\n",
    "        if np.argmax(predictions) == np.argmax(label):\n",
    "            num_correct += 1\n",
    "        \n",
    "        if total_seen % 1000 == 0:\n",
    "            print(\"Accuracy after %i images: %f\" % (total_seen, float(num_correct) / float(total_seen)))\n",
    "    \n",
    "    return float(num_correct) / float(total_seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.989000\n",
      "Accuracy after 2000 images: 0.990500\n",
      "Accuracy after 3000 images: 0.989667\n",
      "Accuracy after 4000 images: 0.990000\n",
      "Accuracy after 5000 images: 0.990400\n",
      "Accuracy after 6000 images: 0.991167\n",
      "Accuracy after 7000 images: 0.991714\n",
      "Accuracy after 8000 images: 0.992750\n",
      "Accuracy after 9000 images: 0.993556\n",
      "Accuracy after 10000 images: 0.993600\n",
      "0.9936\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(interpreter, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its performance was not affected! Great!\n",
    "<h2>Demonstrating How the Pruned Model Works With Other Optimization Techniques, Like Post-Training Quantization</h2>\n",
    "<br/>\n",
    "It is possible to combine pruning with other optimization techniques like Post Training Quantization.\n",
    "<br/>\n",
    "<br/>\n",
    "<b>What is Post Training Quantization?</b>\n",
    "<br/>\n",
    "<br/>\n",
    "Post Training Quantization converts weights to 8 bit precision as part of model conversion from keras model to TFLite's flat buffer, resulting in a 4x reduction in the model size. \n",
    "<a href='https://github.com/kleyersoma/GuideForPostTrainingQuantization' target=\"_blank\">Check this Guide for Post Training Quantization</a>.\n",
    "<br/>\n",
    "<br/>\n",
    "In the following example, <code>the_final whole_pruned_model</code> is taken, converted with Post Training Quantization, check the size reduction and validate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_whole_pruned_model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "tflite_quant_model_file = 'C:/Users/kleye/AppData/Local/Temp/mpzeb2lnfofinal_whole_pruned_model.tflite'\n",
    "with open(tflite_quant_model_file, 'wb') as f:\n",
    "    f.write(converter.convert())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how its size was affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 3.13 Mb\n",
      "Size of the tflite model after compression: 0.57 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(tflite_quant_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" % (os.path.getsize(tflite_quant_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantized model has a size of roughly 1/4 of the orignial one, it is <b>+21.96</b> times lighter than the original model for <code>TensroFlow</code> and for the <code>TensorFlow Lite</code> it is <b>+5.49</b> times lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating the Performance Of a Whole Prune Compressed Post-Training Quantized TensorFlow Lite Model</h3>\n",
    "<br/>\n",
    "As it was done before, the class <code>Interpreter</code> is invoked, its tensors are allocate by <code>allocate_tensors()</code>, the input details are obtained by the function <code>get_input_details()</code>, the output details are obtained by the function <code>get_output_details()</code> and the method <code>eval_model()</code>, runs the evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.989000\n",
      "Accuracy after 2000 images: 0.990500\n",
      "Accuracy after 3000 images: 0.989667\n",
      "Accuracy after 4000 images: 0.990000\n",
      "Accuracy after 5000 images: 0.990400\n",
      "Accuracy after 6000 images: 0.991167\n",
      "Accuracy after 7000 images: 0.991714\n",
      "Accuracy after 8000 images: 0.992750\n",
      "Accuracy after 9000 images: 0.993556\n",
      "Accuracy after 10000 images: 0.993700\n",
      "0.9937\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "print(eval_model(interpreter, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lighter, faster and preciser, the model is performing even better.\n",
    "<br/>\n",
    "<br/>\n",
    "To the stellar duo of Pruning and Compressing, a new technique partners with them, it is Post Training Quantization, <i>they are  definetly a hot thresome!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr>\n",
    "<br/>\n",
    "<h2>Conclusion</h2>\n",
    "<br/>\n",
    "    This notebooks, teaches how to create sparse models with the TensorFlow model optimization toolkit weight pruning API.\n",
    "    This allows to create models that take significant less space on disk.\n",
    "    <i><b>The resulting model can also be more efficiently implemented to avoid computation; in the future TensorFlow Lite will \n",
    "    provide such capabilities.</i></b>\n",
    "    <br/>\n",
    "    <br/>\n",
    "    In this notebook, step by step explained through an end-to-end example of training a simple MNIST model that used the \n",
    "    weight pruning API. The notebook teaches how to convert a model to the Tensorflow Lite format for mobile deployment, and \n",
    "    demonstrated how with simple file compression the model size was even reduced +5 times.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    <b>This new capability on Keras models can be particularly important for deployment in resource-constraint environments.\n",
    "    </b>\n",
    "<h2><i><a href='https://www.tensorflow.org/model_optimization/guide/pruning'>Tips from the official docs</a></i></h2>\n",
    "<ul>\n",
    "    <li>Start with a pre-trained model or weights if possible. If not, create one without pruning and start after.</li>\n",
    "    <li>Do not prune very frequently to give the model time to recover. </i>The toolkit provides a default frequency!</i></li>\n",
    "    <li>Try running an experiment where pruning a pre-trained model to the final sparsity with begin step 0.</li>\n",
    "    <li>Have a learning rate that's not too high or too low when the model is pruning. <b><i>Consider the pruning schedule to be a \n",
    "        hyperparameter</i></b>.</li>\n",
    "</ul>\n",
    "<h2>References</h2>\n",
    "<ul>\n",
    "    <li><a href='https://arxiv.org/pdf/1710.01878.pdf'>To prune, or not to prune: exploring the efficacy of pruning for model compression</a>, by Michael H. Zhu and Suyog Gupta.</li>\n",
    "    <li><a href='https://www.tensorflow.org/model_optimization/guide/pruning'>Tensorflow Model Optimization Guide to Pruning with Keras</a>.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
